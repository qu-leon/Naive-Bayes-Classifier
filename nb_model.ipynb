{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3524\\2679096259.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mcount_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#limit to 5000 unique words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mX_train_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;31m# print(count_vect.vocabulary_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\leon_\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m         \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\leon_\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1202\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\leon_\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\leon_\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    227\u001b[0m                 \u001b[1;34m\"np.nan is an invalid document, expected byte or unicode string.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"cleaned_news.csv\")\n",
    "df.head()\n",
    "\n",
    "DV = \"fake_news\"\n",
    "X = df.drop([DV], axis=1)\n",
    "y = df[DV]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "count_vect = CountVectorizer(max_features= 5000) #limit to 5000 unique words\n",
    "X_train_counts = count_vect.fit_transform(X_train[\"text\"])\n",
    "# print(count_vect.vocabulary_)\n",
    "X_test = count_vect.transform(X_test[\"text\"])\n",
    "\n",
    "# fit the training dataset on the NB classifier\n",
    "Naive = MultinomialNB()\n",
    "Naive.fit(X_train_counts, y_train)\n",
    "\n",
    "#predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(X_test)\n",
    "print(\"Accuracy Score:\", accuracy_score(predictions_NB, y_test)*100)\n",
    "\n",
    "# real life article prediction\n",
    "# link: https://entertainment.theonion.com/drake-fans-accuse-kenny-chesney-of-manipulating-billboa-1843484082\n",
    "onion = [\"\"\"Calling the country singer’s place at the top of Top 200 completely illegitimate, fans of the \n",
    "            rapper–singer Drake took to social media Friday to accuse Kenny Chesney of manipulating Billboard’s \n",
    "            algorithm by putting effort into his album. “It’s just unfair that this guy could keep Drake from his\n",
    "            rightful place on the charts by putting out quality music that he actually cares about,” said Aiden \n",
    "            Howard, 14, who echoed the sentiments of Drake fans worldwide in his assertion that the artist’s \n",
    "            mediocre B-sides deserved more acclaim and recognition. “He clearly gamed the streaming numbers when \n",
    "            he decided to put time and energy into his craft. It’s such horseshit that Billboard rewards that \n",
    "            behavior and punishes Drizzy for making a half-assed mixtape full of songs he’d already dropped on \n",
    "            SoundCloud. How the hell is ‘Toosie Slide’ going to compare to a song that the artist thought about \n",
    "            for more than 15 minutes?” At press time, Drake released a statement asking fans to ignore Kenny \n",
    "            Chesney and focus on the horseshit that he just released.\"\"\"]\n",
    "\n",
    "onion_vec = count_vect.transform(onion)\n",
    "predict_onion = Naive.predict(onion_vec)\n",
    "print(predict_onion)\n",
    "\n",
    "# link: https://www.nytimes.com/2020/05/16/us/politics/linick-investigation-pompeo.html?action=click&module=Top%20Stories&pgtype=Homepage\n",
    "nyt = [\"\"\"Two top congressional Democrats opened an investigation on Saturday into President Trump’s removal of \n",
    "          Steve A. Linick, who led the office of the inspector general at the State Department, citing a pattern \n",
    "          of “politically-motivated firing of inspectors general.” Mr. Trump told Speaker Nancy Pelosi late \n",
    "          Friday night that he was ousting Mr. Linick, who was named by President Barack Obama to the State \n",
    "          Department post, and replacing him with an ambassador with close ties to Vice President Mike Pence in \n",
    "          the latest purge of inspectors general whom Mr. Trump has deemed insufficiently loyal to his \n",
    "          administration. In letters to the White House, State Department, and Mr. Linick, Representative Eliot \n",
    "          L. Engel of New York, the chairman of the House Foreign Affairs Committee, and Senator Bob Menendez of \n",
    "          New Jersey, the top Democrat on the Senate Foreign Relations Committee, requested that the administration\n",
    "          turn over records and information related to the firing of Mr. Linick as well as “records of all I.G. \n",
    "          investigations involving the Office of the Secretary that were open, pending, or incomplete at the \n",
    "          time of Mr. Linick’s firing.” Mr. Engel and Mr. Menendez said in their letters that they believe \n",
    "          Secretary of State Mike Pompeo recommended Mr. Linick’s ouster because he had opened an investigation \n",
    "          into Mr. Pompeo’s conduct. The lawmakers did not provide any more details, but a Democratic aide said \n",
    "          that Mr. Linick had been looking into whether Mr. Pompeo had misused a political appointee at the State \n",
    "          Department to perform personal tasks for himself and his wife. “Such an action, transparently designed to\n",
    "          protect Secretary Pompeo from personal accountability, would undermine the foundation of our democratic \n",
    "          institutions and may be an illegal act of retaliation,” the lawmakers wrote. Under law, the administration\n",
    "          must notify Congress 30 days before formally terminating an inspector general. Mr. Linick is expected to \n",
    "          leave his post then. Mr. Trump’s decision to remove Mr. Linick is the latest in a series of ousters aimed\n",
    "          at inspectors general who the president and his allies believe are opposed to his agenda. In May, Mr. \n",
    "          Trump moved to oust Christi A. Grimm, the principal deputy inspector general for the Department of Health\n",
    "          and Human Services, whose office had issued a report revealing the dire state of the nation’s response to\n",
    "          the pathogen. He has also taken steps to remove two other inspectors general, for the intelligence\n",
    "          community and for the Defense Department. Mr. Linick was spotlighted during the impeachment inquiry when \n",
    "          he requested an urgent meeting with congressional staff members to give them copies of documents related \n",
    "          to the State Department and Ukraine, signaling they could be relevant to the House investigation into \n",
    "          whether President Trump pressured Ukraine to investigate former Vice President Joseph R. Biden Jr. and \n",
    "          his son Hunter Biden. The documents — a record of contacts between Rudolph W. Giuliani, the president’s \n",
    "          personal lawyer, and Ukrainian prosecutors, as well as accounts of Ukrainian law enforcement proceedings \n",
    "          — turned out to be largely inconsequential.\"\"\"]\n",
    "\n",
    "nyt_vec = count_vect.transform(nyt)\n",
    "predict_nyt = Naive.predict(nyt_vec)\n",
    "print(predict_nyt)\n",
    "\n",
    "def classifier(text):\n",
    "    Naive = MultinomialNB()\n",
    "    Naive.fit(X_train_counts, y_train)\n",
    "    \n",
    "    # n.b: you may need to wrap the argument in brackets to make it a vector if you passed in a string\n",
    "    word_vec = count_vect.transform(text) \n",
    "    \n",
    "    predict = Naive.predict(word_vec)\n",
    "    return \"Fake News Story\" if predict[0] else \"Real News Story\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
